{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import cv2\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from IPython.display import display\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "import os\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdbad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"D:\\project\\Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3dbe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe = pd.read_csv('data_mask.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b964dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f53ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6733b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe.mask_path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aacb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe.image_path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe['mask'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure([go.Bar(x = brain_dataframe['mask'].value_counts().index, y = brain_dataframe['mask'].value_counts())])\n",
    "fig.update_traces(marker_color = 'rgb(51,51,255)', marker_line_color = 'rgb(0,0,0)',marker_line_width = 2, opacity = 0.6)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "round((brain_dataframe['mask'].value_counts()* 100 / len(brain_dataframe['mask'])),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24807c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe.mask_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe.image_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cv2.imread(brain_dataframe.mask_path[2490]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1136af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cv2.imread(brain_dataframe.image_path[2490]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b333c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(brain_dataframe.mask_path[2490]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(brain_dataframe.mask_path[2490]).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6c4c0",
   "metadata": {},
   "source": [
    "# Basic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2dd1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "fig, axis = plt.subplots(5,2, figsize=(20,40))\n",
    "count = 0\n",
    "for x in range(5):\n",
    "  i = random.randint(0, len(brain_dataframe)) # select a random index \n",
    "  axis[count][0].title.set_text(\"Brain MRI\") # set title\n",
    "  axis[count][0].imshow(cv2.imread(brain_dataframe.image_path[i])) # show MRI \n",
    "  axis[count][1].title.set_text(\"Mask : \" + str(brain_dataframe['mask'][i])) # plot title on the mask (0 or 1)\n",
    "  axis[count][1].imshow(cv2.imread(brain_dataframe.mask_path[i])) # Show corresponding mask\n",
    "  count += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3c3ef",
   "metadata": {},
   "source": [
    "# Advanced Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68bf2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "fig, axis = plt.subplots(10, 3, figsize = (20, 40))\n",
    "for i in range(len(brain_dataframe)):\n",
    "  if brain_dataframe['mask'][i] ==1 and count <10:\n",
    "    img = io.imread(brain_dataframe.image_path[i])\n",
    "    axis[count][0].title.set_text('Brain MRI')\n",
    "    axis[count][0].imshow(img)\n",
    "\n",
    "    mask = io.imread(brain_dataframe.mask_path[i])\n",
    "    axis[count][1].title.set_text('Mask')\n",
    "    axis[count][1].imshow(mask, cmap = 'gray')\n",
    "\n",
    "    \n",
    "    img[mask == 255] = (255, 0, 0)\n",
    "    axis[count][2].title.set_text('MRI with Mask')\n",
    "    axis[count][2].imshow(img)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d8f1f",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65860b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe_train = brain_dataframe.drop(columns = ['patient_id'])\n",
    "brain_dataframe_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe_train['mask'] = brain_dataframe_train['mask'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d04789",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(brain_dataframe_train, test_size = 0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678eecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255., validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train,\n",
    "directory= './',\n",
    "x_col='image_path',\n",
    "y_col='mask',\n",
    "subset=\"training\",\n",
    "batch_size=16,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(256,256))\n",
    "\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train,\n",
    "directory= './',\n",
    "x_col='image_path',\n",
    "y_col='mask',\n",
    "subset=\"validation\",\n",
    "batch_size=16,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(256,256))\n",
    "\n",
    "# Create a data generator for test images\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test,\n",
    "directory= './',\n",
    "x_col='image_path',\n",
    "y_col='mask',\n",
    "batch_size=16,\n",
    "shuffle=False,\n",
    "class_mode='categorical',\n",
    "target_size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0158b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel =DenseNet121(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b73d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in basemodel.layers:\n",
    "  layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dcd056",
   "metadata": {},
   "outputs": [],
   "source": [
    "headmodel = basemodel.output\n",
    "headmodel = AveragePooling2D(pool_size = (4,4))(headmodel)\n",
    "headmodel = Flatten(name= 'flatten')(headmodel)\n",
    "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
    "headmodel = Dropout(0.25)(headmodel)#\n",
    "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
    "headmodel = Dropout(0.25)(headmodel)\n",
    "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
    "headmodel = Dropout(0.25)(headmodel)\n",
    "headmodel = Dense(2, activation = 'softmax')(headmodel)\n",
    "\n",
    "model = Model(inputs = basemodel.input, outputs = headmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48458c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor='val_loss', \n",
    "                              mode='min', \n",
    "                              verbose=1, \n",
    "                              patience=25\n",
    "                             )\n",
    "checkpointer = ModelCheckpoint(filepath=\"D:\\project\\Dataset\\Model\\Classifier_DenseNet_Model.hdf5\", \n",
    "                               verbose=1, \n",
    "                               save_best_only=True\n",
    "                              )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              verbose=1,\n",
    "                              patience=10,\n",
    "                              min_delta=0.0001,\n",
    "                              factor=0.2\n",
    "                             )\n",
    "callbacks = [checkpointer, earlystopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56122869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "              steps_per_epoch= train_generator.n // train_generator.batch_size, \n",
    "              epochs = 100, \n",
    "              validation_data= valid_generator, \n",
    "              validation_steps= valid_generator.n // valid_generator.batch_size, \n",
    "              callbacks = [checkpointer, earlystopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e37694",
   "metadata": {},
   "outputs": [],
   "source": [
    "csfont = {'fontname':'Times New Roman','size':14,'weight':'bold'}\n",
    "plt.figure(figsize = [15, 5])\n",
    "sns.set_style('whitegrid')\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy',**csfont)\n",
    "plt.ylabel('Accuracy',**csfont)\n",
    "plt.xlabel('Epoch',**csfont)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec897d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "csfont = {'fontname':'Times New Roman','size':14,'weight':'bold'}\n",
    "plt.figure(figsize = [15, 5])\n",
    "sns.set_style('whitegrid')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss',**csfont)\n",
    "plt.ylabel('Loss',**csfont)\n",
    "plt.xlabel('Epoch',**csfont)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ca786",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a68cb4",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"D:\\project\\Dataset\\Model\\classifierDensenetmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9fd4d",
   "metadata": {},
   "source": [
    "# Assess Trained Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\project\\Dataset\\Model\\classifierDensenetmodel.json', 'r') as json_file:\n",
    "    json_savedModel= json_file.read()\n",
    "# load the model  \n",
    "model = tf.keras.models.model_from_json(json_savedModel)\n",
    "model.load_weights('D:\\project\\Dataset\\Model\\Classifier_DenseNet_Model.hdf5')\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(test_generator, steps = test_generator.n // 16, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a27237",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd02c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c11e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "\n",
    "for i in test_predict:\n",
    "  predict.append(str(np.argmax(i)))\n",
    "\n",
    "predict = np.asarray(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = np.asarray(test['mask'])[:len(predict)]\n",
    "len(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6451c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = round(accuracy_score(original, predict),2)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(original, predict)\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.heatmap(cm, annot=True,fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(original, predict, labels = [0,1])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646fed3d",
   "metadata": {},
   "source": [
    "# BUILD A SEGMENTATION MODEL TO LOCALIZE TUMOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataframe_mask = brain_dataframe[brain_dataframe['mask'] == 1]\n",
    "brain_dataframe_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(brain_dataframe_mask, test_size=0.2,random_state=42)\n",
    "X_test, X_val = train_test_split(X_val, test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ids = list(X_train.image_path)\n",
    "train_mask = list(X_train.mask_path)\n",
    "\n",
    "val_ids = list(X_val.image_path)\n",
    "val_mask= list(X_val.mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import DataGenerator\n",
    "\n",
    "# create image generators\n",
    "\n",
    "training_generator = DataGenerator(train_ids,train_mask)\n",
    "validation_generator = DataGenerator(val_ids,val_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resblock(X, f):\n",
    "  \n",
    "\n",
    "  # make a copy of input\n",
    "    X_copy = X\n",
    "\n",
    "  # main path\n",
    "  # Read more about he_normal: https://medium.com/@prateekvishnu/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528\n",
    "\n",
    "    X = Conv2D(f, kernel_size = (1,1) ,strides = (1,1),kernel_initializer ='he_normal')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    X = Conv2D(f, kernel_size = (3,3), strides =(1,1), padding = 'same', kernel_initializer ='he_normal')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "\n",
    "  # Short path\n",
    "  # Read more here: https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33\n",
    "\n",
    "    X_copy = Conv2D(f, kernel_size = (1,1), strides =(1,1), kernel_initializer ='he_normal')(X_copy)\n",
    "    X_copy = BatchNormalization()(X_copy)\n",
    "\n",
    "  # Adding the output from main path and short path together\n",
    "\n",
    "    X = Add()([X,X_copy])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to upscale and concatenate the values passsed\n",
    "def upsample_concat(x, skip):\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    merge = Concatenate()([x, skip])\n",
    "\n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde77aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256,256,3)\n",
    "\n",
    "# Input tensor shape\n",
    "X_input = Input(input_shape)\n",
    "\n",
    "# Stage 1\n",
    "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(X_input)\n",
    "conv1_in = BatchNormalization()(conv1_in)\n",
    "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(conv1_in)\n",
    "conv1_in = BatchNormalization()(conv1_in)\n",
    "pool_1 = MaxPool2D(pool_size = (2,2))(conv1_in)\n",
    "\n",
    "# Stage 2\n",
    "conv2_in = resblock(pool_1, 32)\n",
    "pool_2 = MaxPool2D(pool_size = (2,2))(conv2_in)\n",
    "\n",
    "# Stage 3\n",
    "conv3_in = resblock(pool_2, 64)\n",
    "pool_3 = MaxPool2D(pool_size = (2,2))(conv3_in)\n",
    "\n",
    "# Stage 4\n",
    "conv4_in = resblock(pool_3, 128)\n",
    "pool_4 = MaxPool2D(pool_size = (2,2))(conv4_in)\n",
    "\n",
    "# Stage 5 (Bottle Neck)\n",
    "conv5_in = resblock(pool_4, 256)\n",
    "\n",
    "# Upscale stage 1\n",
    "up_1 = upsample_concat(conv5_in, conv4_in)\n",
    "up_1 = resblock(up_1, 128)\n",
    "\n",
    "# Upscale stage 2\n",
    "up_2 = upsample_concat(up_1, conv3_in)\n",
    "up_2 = resblock(up_2, 64)\n",
    "\n",
    "# Upscale stage 3\n",
    "up_3 = upsample_concat(up_2, conv2_in)\n",
    "up_3 = resblock(up_3, 32)\n",
    "\n",
    "# Upscale stage 4\n",
    "up_4 = upsample_concat(up_3, conv1_in)\n",
    "up_4 = resblock(up_4, 16)\n",
    "\n",
    "# Final Output\n",
    "output = Conv2D(1, (1,1), padding = \"same\", activation = \"sigmoid\")(up_4)\n",
    "\n",
    "model_seg = Model(inputs = X_input, outputs = output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ec69c",
   "metadata": {},
   "source": [
    "# Train a Segmentation Resunet Model to Localize Tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b81352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import tversky_loss, tversky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_tversky(y_true,y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    #print(type(y_pred))\n",
    "    pt_1 = tversky(y_true, y_pred)\n",
    "    gamma = 0.75\n",
    "    return K.pow((1-pt_1), gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e8181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compling model and callbacks functions\n",
    "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
    "model_seg.compile(optimizer = adam, \n",
    "                  loss = focal_tversky, \n",
    "                  metrics = [tversky]\n",
    "                 )\n",
    "#callbacks\n",
    "earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                              mode='min', \n",
    "                              verbose=1, \n",
    "                              patience=25\n",
    "                             )\n",
    "# save the best model with lower validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"D:\\project\\Dataset\\Model\\DenseNet_ResUNet-weights.hdf5\", \n",
    "                               verbose=1, \n",
    "                               save_best_only=True\n",
    "                              )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              verbose=1,\n",
    "                              patience=10,\n",
    "                              min_delta=0.0001,\n",
    "                              factor=0.2\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbba8b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model_seg.fit(training_generator, epochs = 100, validation_data = validation_generator,\n",
    "                        callbacks = [checkpointer, earlystopping,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csfont = {'fontname':'Times New Roman','size':14,'weight':'bold'}\n",
    "plt.figure(figsize = [15, 5])\n",
    "sns.set_style('whitegrid')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss',**csfont)\n",
    "plt.ylabel('Loss',**csfont)\n",
    "plt.xlabel('Epoch',**csfont)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csfont = {'fontname':'Times New Roman','size':14,'weight':'bold'}\n",
    "plt.figure(figsize = [15, 5])\n",
    "sns.set_style('whitegrid')\n",
    "plt.plot(history.history['tversky'])\n",
    "plt.plot(history.history['val_tversky'])\n",
    "plt.title('Model tversky',**csfont)\n",
    "plt.ylabel('tversky',**csfont)\n",
    "plt.xlabel('Epoch',**csfont)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model architecture to json file for future use\n",
    "\n",
    "model_json = model_seg.to_json()\n",
    "with open(\"D:\\project\\Dataset\\Model\\DenseNet-model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60dc6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import focal_tversky, tversky_loss, tversky\n",
    "\n",
    "with open('D:\\project\\Dataset\\Model\\DenseNet-model.json', 'r') as json_file:\n",
    "    json_savedModel= json_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg1 = tf.keras.models.model_from_json(json_savedModel)\n",
    "model_seg1.load_weights('D:\\project\\Dataset\\Model\\DenseNet_ResUNet-weights.hdf5')\n",
    "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
    "model_seg1.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974459d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utilities file contains the code for custom loss function and custom data generator\n",
    "from utilities import prediction\n",
    "\n",
    "# making prediction\n",
    "image_id, mask, has_mask = prediction(test, model, model_seg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1619bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe for the result\n",
    "df_pred = pd.DataFrame({'image_path': image_id,'predicted_mask': mask,'has_mask': has_mask})\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ba455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframe containing predicted results with the original test data.\n",
    "df_pred = test.merge(df_pred, on = 'image_path')\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 \n",
    "fig, axs = plt.subplots(12, 5, figsize=(30,90))\n",
    "for i in range(len(df_pred)):\n",
    "    if df_pred['has_mask'][i] == 1 and count < 12:\n",
    "        # read the images and convert them to RGB format\n",
    "        img = io.imread(df_pred.image_path[i])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axs[count][0].title.set_text(\"Brain MRI\")\n",
    "        axs[count][0].imshow(img)\n",
    "\n",
    "        # Obtain the mask for the image \n",
    "        mask = io.imread(df_pred.mask_path[i])\n",
    "        axs[count][1].title.set_text(\"Original Mask\")\n",
    "        axs[count][1].imshow(mask)\n",
    "\n",
    "        # Obtain the predicted mask for the image \n",
    "        predicted_mask = np.asarray(df_pred.predicted_mask[i])[0].squeeze().round()\n",
    "        axs[count][2].title.set_text(\"AI Predicted Mask\")\n",
    "        axs[count][2].imshow(predicted_mask)\n",
    "\n",
    "        # Apply the mask to the image 'mask==255'\n",
    "        img[mask == 255] = (255, 0, 0)\n",
    "        axs[count][3].title.set_text(\"MRI with Original Mask (Ground Truth)\")\n",
    "        axs[count][3].imshow(img)\n",
    "\n",
    "        img_ = io.imread(df_pred.image_path[i])\n",
    "        img_ = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)\n",
    "        img_[predicted_mask == 1] = (0, 255, 0)\n",
    "        axs[count][4].title.set_text(\"MRI with AI Predicted Mask\")\n",
    "        axs[count][4].imshow(img_)\n",
    "        count += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f367bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99290f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
